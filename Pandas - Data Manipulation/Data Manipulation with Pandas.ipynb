{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a4d2d1-83b2-476a-824c-d17894db7bd3",
   "metadata": {},
   "source": [
    "# Data Manipulation with pandas\n",
    "\n",
    "**Description**\n",
    "\n",
    "pandas is the world's most popular Python library, used for everything from data manipulation to data analysis. In this course, you'll learn how to manipulate DataFrames, as you extract, filter, and transform real-world datasets for analysis. Using pandas you’ll explore all the core data science concepts. Using real-world data, including Walmart sales figures and global temperature time series, you’ll learn how to import, clean, calculate statistics, and create visualizations—using pandas to add to the power of Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2943a8-ae9f-40a0-be42-0ab28e662788",
   "metadata": {},
   "source": [
    "## Transforming DataFrames\n",
    "\n",
    "Let’s master the pandas basics. Learn how to inspect DataFrames and perform fundamental manipulations, including sorting rows, subsetting, and adding new columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e0b21-8a3c-4573-bf02-5e1dca9a4884",
   "metadata": {},
   "source": [
    "### Introducing DataFrames\n",
    "\n",
    "1. Introducing DataFrames\n",
    "00:00 - 00:05\n",
    "Hi, I'm Richie. I'll be your tour guide through the world of pandas.\n",
    "\n",
    "2. What's the point of pandas?\n",
    "00:05 - 00:14\n",
    "pandas is a Python package for data manipulation. It can also be used for data visualization; we'll get to that in Chapter 4.\n",
    "\n",
    "3. Course outline\n",
    "00:14 - 00:39\n",
    "We'll start by talking about DataFrames, which form the core of pandas. In chapter 2, we'll discuss aggregating data to gather insights. In chapter 3, you'll learn all about slicing and indexing to subset DataFrames. Finally, you'll visualize your data, deal with missing data, and read data into a DataFrame. Let's dive in.\n",
    "\n",
    "4. pandas is built on NumPy and Matplotlib\n",
    "00:39 - 01:03\n",
    "pandas is built on top of two essential Python packages, NumPy and Matplotlib. Numpy provides multidimensional array objects for easy data manipulation that pandas uses to store data, and Matplotlib has powerful data visualization capabilities that pandas takes advantage of.\n",
    "\n",
    "5. pandas is popular\n",
    "01:03 - 01:16\n",
    "pandas has millions of users, with PyPi recording about 14 million downloads in December 2019. This represents almost the entire Python data science community!\n",
    "\n",
    "1 https://pypistats.org/packages/pandas\n",
    "6. Rectangular data\n",
    "01:16 - 01:42\n",
    "There are several ways to store data for analysis, but rectangular data, sometimes called \"tabular data\" is the most common form. In this example, with dogs, each observation, or each dog, is a row, and each variable, or each dog property, is a column. pandas is designed to work with rectangular data like this.\n",
    "\n",
    "7. pandas DataFrames\n",
    "01:42 - 02:12\n",
    "In pandas, rectangular data is represented as a DataFrame object. Every programming language used for data analysis has something similar to this. R also has DataFrames, while SQL has database tables. Every value within a column has the same data type, either text or numeric, but different columns can contain different data types.\n",
    "\n",
    "8. Exploring a DataFrame: .head()\n",
    "02:12 - 02:38\n",
    "When you first receive a new dataset, you want to quickly explore it and get a sense of its contents. pandas has several methods for this. The first is head, which returns the first few rows of the DataFrame. We only had seven rows to begin with, so it's not super exciting, but this becomes very useful if you have many rows.\n",
    "\n",
    "9. Exploring a DataFrame: .info()\n",
    "02:38 - 02:46\n",
    "The info method displays the names of columns, the data types they contain, and whether they have any missing values.\n",
    "\n",
    "10. Exploring a DataFrame: .shape\n",
    "02:46 - 02:59\n",
    "A DataFrame's shape attribute contains a tuple that holds the number of rows followed by the number of columns. Since this is an attribute instead of a method, you write it without parentheses.\n",
    "\n",
    "11. Exploring a DataFrame: .describe()\n",
    "02:59 - 03:22\n",
    "The describe method computes some summary statistics for numerical columns, like mean and median. \"count\" is the number of non-missing values in each column. describe is good for a quick overview of numeric variables, but if you want more control, you'll see how to perform more specific calculations later in the course.\n",
    "\n",
    "12. Components of a DataFrame: .values\n",
    "03:22 - 03:36\n",
    "DataFrames consist of three different components, accessible using attributes. The values attribute, as you might expect, contains the data values in a 2-dimensional NumPy array.\n",
    "\n",
    "13. Components of a DataFrame: .columns and .index\n",
    "03:36 - 04:12\n",
    "The other two components of a DataFrame are labels for columns and rows. The columns attribute contains column names, and the index attribute contains row numbers or row names. Be careful, since row labels are stored in dot-index, not in dot-rows. Notice that these are Index objects, which we'll cover in Chapter 3. This allows for flexibility in labels. For example, the dogs data uses row numbers, but row names are also possible.\n",
    "\n",
    "14. pandas Philosophy\n",
    "04:12 - 04:56\n",
    "Python has a semi-official philosophy on how to write good code called The Zen of Python. One suggestion is that given a programming problem, there should only be one obvious solution. As you go through this course, bear in mind that pandas deliberately doesn't follow this philosophy. Instead, there are often multiple ways to solve a problem, leaving you to choose the best. In this respect, pandas is like a Swiss Army Knife, giving you a variety of tools, making it incredibly powerful, but more difficult to learn. In this course, we aim for a more streamlined approach to pandas, only covering the most important ways of doing things.\n",
    "\n",
    "1 https://www.python.org/dev/peps/pep-0020/\n",
    "\n",
    "**Inspecting a DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e63a37-fa19-49e2-888a-b4e647420b25",
   "metadata": {},
   "source": [
    "**Sorting and subsetting**\n",
    "\n",
    "1. Introducing DataFrames\n",
    "00:00 - 00:05\n",
    "Hi, I'm Richie. I'll be your tour guide through the world of pandas.\n",
    "\n",
    "2. What's the point of pandas?\n",
    "00:05 - 00:14\n",
    "pandas is a Python package for data manipulation. It can also be used for data visualization; we'll get to that in Chapter 4.\n",
    "\n",
    "3. Course outline\n",
    "00:14 - 00:39\n",
    "We'll start by talking about DataFrames, which form the core of pandas. In chapter 2, we'll discuss aggregating data to gather insights. In chapter 3, you'll learn all about slicing and indexing to subset DataFrames. Finally, you'll visualize your data, deal with missing data, and read data into a DataFrame. Let's dive in.\n",
    "\n",
    "4. pandas is built on NumPy and Matplotlib\n",
    "00:39 - 01:03\n",
    "pandas is built on top of two essential Python packages, NumPy and Matplotlib. Numpy provides multidimensional array objects for easy data manipulation that pandas uses to store data, and Matplotlib has powerful data visualization capabilities that pandas takes advantage of.\n",
    "\n",
    "5. pandas is popular\n",
    "01:03 - 01:16\n",
    "pandas has millions of users, with PyPi recording about 14 million downloads in December 2019. This represents almost the entire Python data science community!\n",
    "\n",
    "1 https://pypistats.org/packages/pandas\n",
    "6. Rectangular data\n",
    "01:16 - 01:42\n",
    "There are several ways to store data for analysis, but rectangular data, sometimes called \"tabular data\" is the most common form. In this example, with dogs, each observation, or each dog, is a row, and each variable, or each dog property, is a column. pandas is designed to work with rectangular data like this.\n",
    "\n",
    "7. pandas DataFrames\n",
    "01:42 - 02:12\n",
    "In pandas, rectangular data is represented as a DataFrame object. Every programming language used for data analysis has something similar to this. R also has DataFrames, while SQL has database tables. Every value within a column has the same data type, either text or numeric, but different columns can contain different data types.\n",
    "\n",
    "8. Exploring a DataFrame: .head()\n",
    "02:12 - 02:38\n",
    "When you first receive a new dataset, you want to quickly explore it and get a sense of its contents. pandas has several methods for this. The first is head, which returns the first few rows of the DataFrame. We only had seven rows to begin with, so it's not super exciting, but this becomes very useful if you have many rows.\n",
    "\n",
    "9. Exploring a DataFrame: .info()\n",
    "02:38 - 02:46\n",
    "The info method displays the names of columns, the data types they contain, and whether they have any missing values.\n",
    "\n",
    "10. Exploring a DataFrame: .shape\n",
    "02:46 - 02:59\n",
    "A DataFrame's shape attribute contains a tuple that holds the number of rows followed by the number of columns. Since this is an attribute instead of a method, you write it without parentheses.\n",
    "\n",
    "11. Exploring a DataFrame: .describe()\n",
    "02:59 - 03:22\n",
    "The describe method computes some summary statistics for numerical columns, like mean and median. \"count\" is the number of non-missing values in each column. describe is good for a quick overview of numeric variables, but if you want more control, you'll see how to perform more specific calculations later in the course.\n",
    "\n",
    "12. Components of a DataFrame: .values\n",
    "03:22 - 03:36\n",
    "DataFrames consist of three different components, accessible using attributes. The values attribute, as you might expect, contains the data values in a 2-dimensional NumPy array.\n",
    "\n",
    "13. Components of a DataFrame: .columns and .index\n",
    "03:36 - 04:12\n",
    "The other two components of a DataFrame are labels for columns and rows. The columns attribute contains column names, and the index attribute contains row numbers or row names. Be careful, since row labels are stored in dot-index, not in dot-rows. Notice that these are Index objects, which we'll cover in Chapter 3. This allows for flexibility in labels. For example, the dogs data uses row numbers, but row names are also possible.\n",
    "\n",
    "14. pandas Philosophy\n",
    "04:12 - 04:56\n",
    "Python has a semi-official philosophy on how to write good code called The Zen of Python. One suggestion is that given a programming problem, there should only be one obvious solution. As you go through this course, bear in mind that pandas deliberately doesn't follow this philosophy. Instead, there are often multiple ways to solve a problem, leaving you to choose the best. In this respect, pandas is like a Swiss Army Knife, giving you a variety of tools, making it incredibly powerful, but more difficult to learn. In this course, we aim for a more streamlined approach to pandas, only covering the most important ways of doing things.\n",
    "\n",
    "1 https://www.python.org/dev/peps/pep-0020/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bff92a-6e2b-4b58-a8dc-ad23beae0019",
   "metadata": {},
   "source": [
    "**New columns**\n",
    "\n",
    "1. New columns\n",
    "00:00 - 00:17\n",
    "In the last lesson, you saw how to subset and sort a DataFrame to extract interesting bits. However, often when you first receive a DataFrame, the contents aren't exactly what you want. You may have to add new columns derived from existing columns.\n",
    "\n",
    "2. Adding a new column\n",
    "00:17 - 00:53\n",
    "Creating and adding new columns can go by many names, including mutating a DataFrame, transforming a DataFrame, and feature engineering. Let's say we want to add a new column to our DataFrame that has each dog's height in meters instead of centimeters. On the left-hand side of the equals, we use square brackets with the name of the new column we want to create. On the right-hand side, we have the calculation. Notice that both the existing column and the new column we just created are in the DataFrame.\n",
    "\n",
    "3. Doggy mass index\n",
    "00:53 - 01:21\n",
    "Let's see what the results are if we calculate the body mass index, or BMI, of these dogs. BMI is usually calculated by taking a person's weight in kilograms and dividing it by their height in meters, squared. Instead of doing this with people, we'll try it out with dogs. Again, the new column is on the left-hand side of the equals, but this time, our calculation involves two columns.\n",
    "\n",
    "4. Multiple manipulations\n",
    "01:21 - 01:56\n",
    "The real power of pandas comes in when you combine all the skills you've learned so far. Let's figure out the names of skinny, tall dogs. First, to define the skinny dogs, we take the subset of the dogs who have a BMI of under 100. Next, we sort the result in descending order of height to get the tallest skinny dogs at the top. Finally, we keep only the columns we're interested in. Here, you can see that Max is the tallest dog with a BMI of under 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240013e3-f485-4914-ae6c-c6ce9c7e41b5",
   "metadata": {},
   "source": [
    "### Aggregating DataFrames\n",
    "\n",
    "In this chapter, you’ll calculate summary statistics on DataFrame columns, and master grouped summary statistics and pivot tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe68cad-b790-4d57-8f31-7a2d8825114b",
   "metadata": {},
   "source": [
    "**Summary statistics**\n",
    "\n",
    "1. Summary statistics\n",
    "00:00 - 00:27\n",
    "Hi, I'm Maggie, and I'll be the other instructor for this course. In the first chapter, you learned about DataFrames, how to sort and subset them, and how to add new columns to them. In this chapter, we'll talk about aggregating data, starting with summary statistics. Summary statistics, as follows from their name, are numbers that summarize and tell you about your dataset.\n",
    "\n",
    "2. Summarizing numerical data\n",
    "00:27 - 00:59\n",
    "One of the most common summary statistics for numeric data is the mean, which is one way of telling you where the \"center\" of your data is. You can calculate the mean of a column by selecting the column with square brackets and calling dot-mean. There are lots of other summary statistics that you can compute on columns, like median and mode, minimum and maximum, and variance and standard deviation. You can also take sums and calculate quantiles.\n",
    "\n",
    "3. Summarizing dates\n",
    "00:59 - 01:17\n",
    "You can also get summary statistics for date columns. For example, we can find the oldest dog's date of birth by taking the minimum of the date of birth column. Similarly, we can take the maximum to see that the youngest dog was born in 2018.\n",
    "\n",
    "4. The .agg() method\n",
    "01:17 - 01:54\n",
    "The aggregate, or agg, method allows you to compute custom summary statistics. Here, we create a function called pct30 that computes the thirtieth percentile of a DataFrame column. Don't worry if this code doesn't make sense to you -- just know that the function takes in a column and spits out the column's thirtieth percentile. Now we can subset the weight column and call dot-agg, passing in the name of our function, pct30. It gives us the thirtieth percentile of the dogs' weights.\n",
    "\n",
    "5. Summaries on multiple columns\n",
    "01:54 - 02:05\n",
    "agg can also be used on more than one column. By selecting the weight and height columns before calling agg, we get the thirtieth percentile for both columns.\n",
    "\n",
    "6. Multiple summaries\n",
    "02:05 - 02:28\n",
    "We can also use agg to get multiple summary statistics at once. Here's another function that computes the fortieth percentile called pct40. We can pass a list of functions into agg, in this case, pct30 and pct40, which will return the thirtieth and fortieth percentiles of the dogs' weights.\n",
    "\n",
    "7. Cumulative sum\n",
    "02:28 - 03:05\n",
    "pandas also has methods for computing cumulative statistics, for example, the cumulative sum. Calling cumsum on a column returns not just one number, but a number for each row of the DataFrame. The first number returned, or the number in the zeroth index, is the first dog's weight. The next number is the sum of the first and second dogs' weights. The third number is the sum of the first, second, and third dogs' weights, and so on. The last number is the sum of all the dogs' weights.\n",
    "\n",
    "8. Cumulative statistics\n",
    "03:05 - 03:20\n",
    "pandas also has methods for other cumulative statistics, such as the cumulative maximum, cumulative minimum, and the cumulative product. These all return an entire column of a DataFrame, rather than a single number.\n",
    "\n",
    "9. Walmart\n",
    "03:20 - 03:53\n",
    "In this chapter, you'll be working with data on Walmart stores, which is a chain of department stores in the US. The dataset contains weekly sales in US dollars in various stores. Each store has an ID number and a specific store type. The sales are also separated by department ID. Along with weekly sales, there is information about whether it was a holiday week or not, the average temperature during the week in that location, the average fuel price in dollars per liter that week, and the national unemployment rate that week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33393868-a229-4ffa-9f47-3352fa7f48f2",
   "metadata": {},
   "source": [
    "**Counting**\n",
    "\n",
    "1. Counting\n",
    "00:00 - 00:10\n",
    "So far, in this chapter, you've learned how to summarize numeric variables. In this video, you'll learn how to summarize categorical data using counting.\n",
    "\n",
    "2. Avoiding double counting\n",
    "00:10 - 00:19\n",
    "Counting dogs is no easy task when they're running around the park. It's hard to keep track of who you have and haven't counted!\n",
    "\n",
    "3. Vet visits\n",
    "00:19 - 00:38\n",
    "Here's a DataFrame that contains vet visits. The vet's office wants to know how many dogs of each breed have visited their office. However, some dogs have been to the vet more than once, like Max and Stella, so we can't just count the number of each breed in the breed column.\n",
    "\n",
    "4. Dropping duplicate names\n",
    "00:38 - 01:21\n",
    "Let's try to fix this by removing rows that contain a dog name already listed earlier in the dataset, or in other words; we'll extract a dog with each name from the dataset once. We can do this using the drop_duplicates method. It takes an argument, subset, which is the column we want to find our duplicates based on - in this case, we want all the unique names. Now we have a list of dogs where each one appears once. We have Max the Chow Chow, but where did Max the Labrador go? Because we have two different dogs with the same name, we'll need to consider more than just name when dropping duplicates.\n",
    "\n",
    "5. Dropping duplicate pairs\n",
    "01:21 - 01:44\n",
    "Since Max and Max are different breeds, we can drop the rows with pairs of name and breed listed earlier in the dataset. To base our duplicate dropping on multiple columns, we can pass a list of column names to the subset argument, in this case, name and breed. Now both Maxes have been included, and we can start counting.\n",
    "\n",
    "6. Easy as 1, 2, 3\n",
    "01:44 - 01:57\n",
    "To count the dogs of each breed, we'll subset the breed column and use the value_counts method. We can also use the sort argument to get the breeds with the biggest counts on top.\n",
    "\n",
    "7. Proportions\n",
    "01:57 - 02:06\n",
    "The normalize argument can be used to turn the counts into proportions of the total. 25% of the dogs that go to this vet are Labradors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88753e7-c76b-4a96-8f77-cb703c7671c7",
   "metadata": {},
   "source": [
    "**Grouped summary statistics**\n",
    "\n",
    "1. Grouped summary statistics\n",
    "00:00 - 00:09\n",
    "So far, you've been calculating summary statistics for all rows of a dataset, but summary statistics can be useful to compare different groups.\n",
    "\n",
    "2. Summaries by group\n",
    "00:09 - 00:43\n",
    "While computing summary statistics of entire columns may be useful, you can gain many insights from summaries of individual groups. For example, does one color of dog weigh more than another on average? Are female dogs taller than males? You can already answer these questions with what you've learned so far! We can subset the dogs into groups based on their color, and take the mean of each. But that's a lot of work, and the duplicated code means you can easily introduce copy and paste bugs.\n",
    "\n",
    "3. Grouped summaries\n",
    "00:43 - 01:01\n",
    "That's where the groupby method comes in. We can group by the color variable, select the weight column, and take the mean. This will give us the mean weight for each dog color. This was just one line of code compared to the five we had to write before to get the same results.\n",
    "\n",
    "4. Multiple grouped summaries\n",
    "01:01 - 01:20\n",
    "Just like with ungrouped summary statistics, we can use the agg method to get multiple statistics. Here, we pass a list of functions into agg after grouping by color. This gives us the minimum, maximum, and sum of the different colored dogs' weights.\n",
    "\n",
    "5. Grouping by multiple variables\n",
    "01:20 - 01:34\n",
    "You can also group by multiple columns and calculate summary statistics. Here, we group by color and breed, select the weight column and take the mean. This gives us the mean weight of each breed of each color.\n",
    "\n",
    "6. Many groups, many summaries\n",
    "01:34 - 01:40\n",
    "You can also group by multiple columns and aggregate by multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407db49f-194b-47c3-8e4d-02a831406132",
   "metadata": {},
   "source": [
    "**Pivot tables**\n",
    "\n",
    "1. Pivot tables\n",
    "00:00 - 00:13\n",
    "Pivot tables are another way of calculating grouped summary statistics. If you've ever used a spreadsheet, chances are you've used a pivot table. Let's see how to create pivot tables in pandas.\n",
    "\n",
    "2. Group by to pivot table\n",
    "00:13 - 00:37\n",
    "In the last lesson, we grouped the dogs by color and calculated their mean weights. We can do the same thing using the pivot_table method. The \"values\" argument is the column that you want to summarize, and the index column is the column that you want to group by. By default, pivot_table takes the mean value for each group.\n",
    "\n",
    "3. Different statistics\n",
    "00:37 - 00:50\n",
    "If we want a different summary statistic, we can use the aggfunc argument and pass it a function. Here, we take the median for each dog color using NumPy's median function.\n",
    "\n",
    "4. Multiple statistics\n",
    "00:50 - 01:02\n",
    "To get multiple summary statistics at a time, we can pass a list of functions to the aggfunc argument. Here, we get the mean and median for each dog color.\n",
    "\n",
    "5. Pivot on two variables\n",
    "01:02 - 01:34\n",
    "You also previously computed the mean weight grouped by two variables: color and breed. We can also do this using the pivot_table method. To group by two variables, we can pass a second variable name into the columns argument. While the result looks a little different than what we had before, it contains the same numbers. There are NaNs, or missing values, because there are no black Chihuahuas or gray Labradors in our dataset, for example.\n",
    "\n",
    "6. Filling missing values in pivot tables\n",
    "01:34 - 01:47\n",
    "Instead of having lots of missing values in our pivot table, we can have them filled in using the fill_value argument. Here, all of the NaNs get filled in with zeros.\n",
    "\n",
    "7. Summing with pivot tables\n",
    "01:47 - 02:39\n",
    "If we set the margins argument to True, the last row and last column of the pivot table contain the mean of all the values in the column or row, not including the missing values that were filled in with Os. For example, in the last row of the Labrador column, we can see that the mean weight of the Labradors is 26 kilograms. In the last column of the Brown row, the mean weight of the Brown dogs is 24 kilograms. The value in the bottom right, in the last row and last column, is the mean weight of all the dogs in the dataset. Using margins equals True allows us to see a summary statistic for multiple levels of the dataset: the entire dataset, grouped by one variable, by another variable, and by two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5136e4-b2e3-4dbd-af38-04063becd89d",
   "metadata": {},
   "source": [
    "### Slicing and Indexing DataFrames\n",
    "\n",
    "Indexes are supercharged row and column names. Learn how they can be combined with slicing for powerful DataFrame subsetting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfeec3c-1c22-407f-a189-379c83c83311",
   "metadata": {},
   "source": [
    "**Explicit indexes**\n",
    "\n",
    "1. Explicit indexes\n",
    "00:00 - 00:00\n",
    "In chapter one, you saw that DataFrames are composed of three parts: a NumPy array for the data, and two indexes to store the row and column details.\n",
    "\n",
    "2. The dog dataset, revisited\n",
    "00:00 - 00:00\n",
    "Here's the dog dataset again.\n",
    "\n",
    "3. .columns and .index\n",
    "00:00 - 00:00\n",
    "Recall that dot-columns contains an Index object of column names, and dot-index contains an Index object of row numbers.\n",
    "\n",
    "4. Setting a column as the index\n",
    "00:00 - 00:00\n",
    "You can move a column from the body of the DataFrame to the index. This is called \"setting an index,\" and it uses the set_index method. Notice that the output has changed slightly; in particular, a quick visual clue that name is now in the index is that the index values are left-aligned rather than right-aligned.\n",
    "\n",
    "5. Removing an index\n",
    "00:00 - 00:00\n",
    "To undo what you just did, you can reset the index - that is, you remove it. This is done via reset_index.\n",
    "\n",
    "6. Dropping an index\n",
    "00:00 - 00:00\n",
    "reset_index has a drop argument that allows you to discard an index. Here, setting drop to True entirely removes the dog names.\n",
    "\n",
    "7. Indexes make subsetting simpler\n",
    "00:00 - 00:00\n",
    "You may be wondering why you should bother with indexes. The answer is that it makes subsetting code cleaner. Consider this example of subsetting for the rows where the dog is called Bella or Stella. It's a fairly tricky line of code for such a simple task. Now, look at the equivalent when the names are in the index. DataFrames have a subsetting method called \"loc,\" which filters on index values. Here you simply pass the dog names to loc as a list. Much easier!\n",
    "\n",
    "8. Index values don't need to be unique\n",
    "00:00 - 00:00\n",
    "The values in the index don't need to be unique. Here, there are two Labradors in the index.\n",
    "\n",
    "9. Subsetting on duplicated index values\n",
    "00:00 - 00:00\n",
    "Now, if you subset on \"Labrador\" using loc, all the Labrador data is returned.\n",
    "\n",
    "10. Multi-level indexes a.k.a. hierarchical indexes\n",
    "00:00 - 00:00\n",
    "You can include multiple columns in the index by passing a list of column names to set_index. Here, breed and color are included. These are called multi-level indexes, or hierarchical indexes: the terms are synonymous. There is an implication here that the inner level of index, in this case, color, is nested inside the outer level, breed.\n",
    "\n",
    "11. Subset the outer level with a list\n",
    "00:00 - 00:00\n",
    "To take a subset of rows at the outer level index, you pass a list of index values to loc. Here, the list contains Labrador and Chihuahua, and the resulting subset contains all dogs from both breeds.\n",
    "\n",
    "12. Subset inner levels with a list of tuples\n",
    "00:00 - 00:00\n",
    "To subset on inner levels, you need to pass a list of tuples. Here, the first tuple specifies Labrador at the outer level and Brown at the inner level. The resulting rows have to match all conditions from a tuple. For example, the black Labrador wasn't returned because the brown condition wasn't matched.\n",
    "\n",
    "13. Sorting by index values\n",
    "00:00 - 00:00\n",
    "In chapter 1, you saw how to sort the rows of a DataFrame using sort_values. You can also sort by index values using sort_index. By default, it sorts all index levels from outer to inner, in ascending order.\n",
    "\n",
    "14. Controlling sort_index\n",
    "00:00 - 00:00\n",
    "You can control the sorting by passing lists to the level and ascending arguments.\n",
    "\n",
    "15. Now you have two problems\n",
    "00:00 - 00:00\n",
    "Indexes are controversial. Although they simplify subsetting code, there are some downsides. Index values are just data. Storing data in multiple forms makes it harder to think about. There is a concept called \"tidy data,\" where data is stored in tabular form - like a DataFrame. Each row contains a single observation, and each variable is stored in its own column. Indexes violate the last rule since index values don't get their own column. In pandas, the syntax for working with indexes is different from the syntax for working with columns. By using two syntaxes, your code is more complicated, which can result in more bugs. If you decide you don't want to use indexes, that's perfectly reasonable. However, it's useful to know how they work for cases when you need to read other people's code.\n",
    "\n",
    "16. Temperature dataset\n",
    "00:00 - 00:00\n",
    "In this chapter, you'll work with a monthly time series of air temperatures in cities around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f714e9a-a796-4eb0-875d-f1202cb9c587",
   "metadata": {},
   "source": [
    "**Slicing and subsetting with .loc and .iloc**\n",
    "\n",
    "1. Slicing and subsetting with .loc and .iloc\n",
    "00:00 - 00:04\n",
    "Slicing is a technique for selecting consecutive elements from objects.\n",
    "\n",
    "2. Slicing lists\n",
    "00:04 - 00:47\n",
    "Here are the dog breeds, this time as a list. To slice the list, you pass first and last positions separated by a colon into square brackets. Remember that Python positions start from zero, so 2 refers to the third element, Chow Chow. Also remember that the last position, 5, is not included in the slice, so we finish at Labrador, not Chihuahua. If you want the slice to start from the beginning of the list, you can omit the zero. Here, using colon-3 returns the first three elements. Slicing with colon on its own returns the whole list.\n",
    "\n",
    "3. Sort the index before you slice\n",
    "00:47 - 01:03\n",
    "You can also slice DataFrames, but first, you need to sort the index. Here, the dogs dataset has been given a multi-level index of breed and color; then, the index is sorted with sort_index.\n",
    "\n",
    "4. Slicing the outer index level\n",
    "01:03 - 01:33\n",
    "To slice rows at the outer level of an index, you call loc, passing the first and last values separated by a colon. The full dataset is shown on the right for comparison. There are two differences compared to slicing lists. Rather than specifying row numbers, you specify index values. Secondly, notice that the final value is included. Here, Poodle is included in the results.\n",
    "\n",
    "5. Slicing the inner index levels badly\n",
    "01:33 - 01:54\n",
    "The same technique doesn't work on inner index levels. Here, trying to slice from Tan to Grey returns an empty DataFrame instead of the six dogs we wanted. It's important to understand the danger here. pandas doesn't throw an error to let you know that there is a problem, so be careful when coding.\n",
    "\n",
    "6. Slicing the inner index levels correctly\n",
    "01:54 - 02:09\n",
    "The correct approach to slicing at inner index levels is to pass the first and last positions as tuples. Here, the first element to include is a tuple of Labrador and Brown.\n",
    "\n",
    "7. Slicing columns\n",
    "02:09 - 02:42\n",
    "Since DataFrames are two-dimensional objects, you can also slice columns. You do this by passing two arguments to loc. The simplest case involves subsetting columns but keeping all rows. To do this, pass a colon as the first argument to loc. As with slicing lists, a colon by itself means \"keep everything.\" The second argument takes column names as the first and last positions to slice on.\n",
    "\n",
    "8. Slice twice\n",
    "02:42 - 02:55\n",
    "You can slice on rows and columns at the same time: simply pass the appropriate slice to each argument. Here, you see the previous two slices being performed in the same line of code.\n",
    "\n",
    "9. Dog days\n",
    "02:55 - 03:07\n",
    "An important use case of slicing is to subset DataFrames by a range of dates. To demonstrate this, let's set the date_of_birth column as the index and sort by this index.\n",
    "\n",
    "10. Slicing by dates\n",
    "03:07 - 03:14\n",
    "You slice dates with the same syntax as other types. The first and last dates are passed as strings.\n",
    "\n",
    "11. Slicing by partial dates\n",
    "03:14 - 03:41\n",
    "One helpful feature is that you can slice by partial dates. Here, the first and last positions are only specified as 2014 and 2016, with no month or day parts. pandas interprets this as slicing from the start of 2014 to the end of 2016; that is, all dates in 2014, 2015, and 2016.\n",
    "\n",
    "12. Subsetting by row/column number\n",
    "03:41 - 04:08\n",
    "You can also slice DataFrames by row or column number using the iloc method. This uses a similar syntax to slicing lists, except that there are two arguments: one for rows and one for columns. Notice that, like list slicing but unlike loc, the final values aren't included in the slice. In this case, the fifth row and fourth column aren't included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9a119-94f4-4642-9623-4ccd670b120e",
   "metadata": {},
   "source": [
    "**Working with pivot tables**\n",
    "\n",
    "1. Working with pivot tables\n",
    "00:00 - 00:09\n",
    "You saw how to create pivot tables with pandas in chapter two. In this lesson, you'll perform subsetting and calculations on pivot tables.\n",
    "\n",
    "2. A bigger dog dataset\n",
    "00:09 - 00:16\n",
    "Here's a larger version of the dog dataset. The extra dogs mean we have something to compute on.\n",
    "\n",
    "3. Pivoting the dog pack\n",
    "00:16 - 00:42\n",
    "Recall that you create a pivot table by calling dot-pivot_table. The first argument is the column name containing values to aggregate. The index argument lists the columns to group by and display in rows, and the columns argument lists the columns to group by and display in columns. We'll use the default aggregation function, which is mean.\n",
    "\n",
    "4. .loc[] + slicing is a power combo\n",
    "00:42 - 01:00\n",
    "Pivot tables are just DataFrames with sorted indexes. That means that all the fun stuff you've learned so far this chapter can be used on them. In particular, the loc and slicing combination is ideal for subsetting pivot tables, like so.\n",
    "\n",
    "5. The axis argument\n",
    "01:00 - 01:25\n",
    "The methods for calculating summary statistics on a DataFrame, such as mean, have an axis argument. The default value is \"index,\" which means \"calculate the statistic across rows.\" Here, the mean is calculated for each color. That is, \"across the breeds.\" The behavior is the same as if you hadn't specified the axis argument.\n",
    "\n",
    "6. Calculating summary stats across columns\n",
    "01:25 - 01:56\n",
    "To calculate a summary statistic for each row, that is, \"across the columns,\" you set axis to \"columns.\" Here, the mean height is calculated for each breed. That is, \"across the colors.\" For most DataFrames, setting the axis argument doesn't make any sense, since you'll have different data types in each column. Pivot tables are a special case since every column contains the same data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e5adc-25ad-43b4-97a1-6d452e91492f",
   "metadata": {},
   "source": [
    "### Creating and Visualizing DataFrames\n",
    "\n",
    "Learn to visualize the contents of your DataFrames, handle missing data values, and import data from and export data to CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178968e-5a89-407c-a28a-9de700f637b3",
   "metadata": {},
   "source": [
    "**Visualizing your data**\n",
    "\n",
    "1. Visualizing your data\n",
    "00:00 - 00:11\n",
    "Plots are a powerful way to share the insights you've gained from your data. In this lesson, we'll use a bigger dataset of dogs, called dog_pack, to make visualization easier.\n",
    "\n",
    "2. Histograms\n",
    "00:11 - 01:08\n",
    "Remember when we talked about matplotlib at the beginning of the course? We'll need to import matplotlib-dot-pyplot as plt in order to display our visualizations. Just like pd is the standard alias for pandas, plt is the standard alias for matplotlib-dot-pyplot. Let's create a histogram, which shows the distribution of a numeric variable. We can create a histogram of the height variable by selecting the column and calling dot-hist. In order to show the plot, we need to call plt-dot-show. The x-axis represents the heights of the dogs, and the y-axis represents the number of dogs in each height range. By grouping observations into ranges, the histogram allows us to see that there are a lot of dogs around 50 to 60 centimeters tall.\n",
    "\n",
    "3. Histograms\n",
    "01:08 - 01:20\n",
    "We can adjust the number of bars, or bins, using the \"bins\" argument. Increasing or decreasing this can give us a better idea of what the distribution looks like.\n",
    "\n",
    "4. Bar plots\n",
    "01:20 - 01:38\n",
    "Bar plots can reveal relationships between a categorical variable and a numeric variable, like breed and weight. To compute the average weight of each breed, we group by breed, select the weight column, and take the mean, giving us the average weight of each breed.\n",
    "\n",
    "5. Bar plots\n",
    "01:38 - 02:00\n",
    "Now we can create a bar plot from the mean weights using the plot method, setting \"kind\" equal to \"bar.\" Finally, we call plt-dot-show. To add a title to our plot, we can use the title argument of the plot method. It looks like Saint Bernards are the heaviest breed on average! Woof!\n",
    "\n",
    "6. Line plots\n",
    "02:00 - 02:29\n",
    "Line plots are great for visualizing changes in numeric variables over time. Lucky for us, a Labrador named Sully has been weighed by his owner every month - let's see how his weight has changed over the year. We can use the plot method again, but this time, we pass in three arguments: date as x, weight as y, and \"kind\" equals \"line.\" Sully's weight has fluctuated quite a bit over the year!\n",
    "\n",
    "7. Rotating axis labels\n",
    "02:29 - 02:46\n",
    "We may want to rotate the x-axis labels to make the text easier to read. This can be done by passing an angle in degrees with the \"rot\" argument. Here, we rotate the labels by 45 degrees.\n",
    "\n",
    "8. Scatter plots\n",
    "02:46 - 03:10\n",
    "Scatter plots are great for visualizing relationships between two numeric variables. To plot each dog's height versus their weight, we call the plot method with x equal to height_cm, y equal to weight_kg, and \"kind\" equal to \"scatter.\" From our plot, it looks like taller dogs tend to weigh more.\n",
    "\n",
    "9. Layering plots\n",
    "03:10 - 03:28\n",
    "Plots can also be layered on top of one another. For example, we can create a histogram of female dogs' heights, and put a histogram of male dogs' heights on top, then call show. However, we can't tell which color represents which sex.\n",
    "\n",
    "10. Add a legend\n",
    "03:28 - 03:41\n",
    "We can use plt-dot-legend, passing in a list of labels, and then call show. Now we know which color is which, but we can't see what's going on behind the orange histogram.\n",
    "\n",
    "11. Transparency\n",
    "03:41 - 03:56\n",
    "Let's fix this problem by making the histograms translucent. We can use hist's alpha argument, which takes a number. 0 means completely transparent that is, invisible, and 1 means completely opaque.\n",
    "\n",
    "12. Avocados\n",
    "03:56 - 04:08\n",
    "In this chapter, you'll be working with a dataset that contains weekly US avocado sales data, broken down by avocado size, and whether or not the avocados were organic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6eb7da-c3d2-4588-8485-d9fb0a6ff04f",
   "metadata": {},
   "source": [
    "**Missing values**\n",
    "\n",
    "1. Missing values\n",
    "00:00 - 00:06\n",
    "You could be given a DataFrame that has missing values, so it's important to know how to handle them.\n",
    "\n",
    "2. What's a missing value?\n",
    "00:06 - 00:18\n",
    "Most data is not perfect - there's always a possibility that there are some pieces missing from your dataset. For example, maybe on the day that Bella and Cooper's owner weighed them,\n",
    "\n",
    "3. What's a missing value?\n",
    "00:18 - 00:24\n",
    "the scale was broken. Now we have two missing values in our dataset.\n",
    "\n",
    "4. Missing values in pandas DataFrames\n",
    "00:24 - 00:32\n",
    "In a pandas DataFrame, missing values are indicated with N-a-N, which stands for \"not a number.\"\n",
    "\n",
    "5. Detecting missing values\n",
    "00:32 - 00:58\n",
    "When you first get a DataFrame, it's a good idea to get a sense of whether it contains any missing values, and if so, how many. That's where the isna method comes in. When we call isna on a DataFrame, we get a Boolean for every single value indicating whether the value is missing or not, but this isn't very helpful when you're working with a lot of data.\n",
    "\n",
    "6. Detecting any missing values\n",
    "00:58 - 01:15\n",
    "If we chain dot-isna with dot-any, we get one value for each variable that tells us if there are any missing values in that column. Here, we see that there's at least one missing value in the weight column, but not in any of the others.\n",
    "\n",
    "7. Counting missing values\n",
    "01:15 - 01:27\n",
    "Since taking the sum of Booleans is the same thing as counting the number of Trues, we can combine sum with isna to count the number of NaNs in each column.\n",
    "\n",
    "8. Plotting missing values\n",
    "01:27 - 01:47\n",
    "We can use those counts to visualize the missing values in the dataset using a bar plot. Plots like this are more interesting when you have missing data across different variables, while here, only weights are missing. Now that we know there are missing values in the dataset, what can we do about them?\n",
    "\n",
    "9. Removing missing values\n",
    "01:47 - 02:05\n",
    "One option is to remove the rows in the DataFrame that contain missing values. This can be done using the dropna method. However, this may not be ideal if you have a lot of missing data, since that means losing a lot of observations.\n",
    "\n",
    "10. Replacing missing values\n",
    "02:05 - 02:25\n",
    "Another option is to replace missing values with another value. The fillna method takes in a value, and all NaNs will be replaced with this value. There are also many sophisticated techniques for replacing missing values, which you can learn more about in our course about missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5136044-0918-493c-afc4-dd8343118b45",
   "metadata": {},
   "source": [
    "**Creating DataFrames**\n",
    "\n",
    "1. Creating DataFrames\n",
    "00:00 - 00:07\n",
    "Now that you've learned a lot about how to work with pandas DataFrames, how do you get data into a DataFrame in the first place?\n",
    "\n",
    "2. Dictionaries\n",
    "00:07 - 00:52\n",
    "Before creating your own DataFrames, let's talk about dictionaries. A dictionary is a way of storing data in Python. It holds a set of key-value pairs. You can create a dictionary like this, using curly braces. Inside, each key-value pair is written as \"key colon value.\" Let's create a dictionary that holds information about a book. \"Title\" is a key in the dictionary, and \"Charlotte's Web\" is its corresponding value, and so on. You can access values of a dictionary via their keys in square brackets. For example, we can access the value of \"title\" like this.\n",
    "\n",
    "3. Creating DataFrames\n",
    "00:52 - 01:12\n",
    "There are many ways to create DataFrames from scratch, but we'll discuss two ways: from a list of dictionaries and from a dictionary of lists. In the first method, the DataFrame is built up row by row, while in the second method, the DataFrame is built up column by column.\n",
    "\n",
    "4. List of dictionaries - by row\n",
    "01:12 - 02:05\n",
    "We have some new dog data to put into a DataFrame. Let's start with the first method to do this, creating a list of dictionaries. First, we'll create a new list using square brackets to hold our dictionaries. Then, we'll go through the first row of our data and put it in a dictionary. Each key, on the left of each colon, will become a column name. Each value is one dog's data for that column. Here, the first key is \"name,\" which is the first column name, and its corresponding value is \"Ginger,\" the name of the first dog. The second key is the second column name, \"breed,\" and its value is \"Dachshund,\" which is the first dog's breed. Then we have the dog's height and weight. For the next row, we create another dictionary that follows the same format.\n",
    "\n",
    "5. List of dictionaries - by row\n",
    "02:05 - 02:14\n",
    "Now that we have our list of dictionaries, we can pass it into pd-dot-DataFrame to convert it into DataFrame form.\n",
    "\n",
    "6. Dictionary of lists - by column\n",
    "02:14 - 03:20\n",
    "Now let's talk about the dictionary of lists method. When using this method, we need to go through the data column by column. Remember that keys are to the left of a colon, and values are to the right. Each key will be a column name, and each value will be a list of the values in the column. First, we'll create a dictionary using curly braces. Let's start with the first column, which is called \"name,\" so the first key is \"name.\" The value is a list containing each name, from top to bottom. In this case, it's \"Ginger\" and \"Scout.\" Next, we have the \"breed\" column, so we add \"breed\" as a key, and its corresponding value is a list containing \"Dachshund\" and \"Dalmatian.\" Then we have height_cm, which is 22 and 59, and weight_kg, which is 10 and 25. Now that we have our dictionary of lists set up, we can pass it into pd-dot-DataFrame to convert it into a pandas DataFrame.\n",
    "\n",
    "7. Dictionary of lists - by column\n",
    "03:20 - 03:25\n",
    "If we print the new DataFrame, we can see that it's exactly what we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c63c7-011d-499c-9a4e-6440bd3b6cd4",
   "metadata": {},
   "source": [
    "**Reading and writing CSVs**\n",
    "\n",
    "1. Reading and writing CSVs\n",
    "00:00 - 00:15\n",
    "You now know how to create your own DataFrames, but typing out your data entry-by-entry isn't usually the most efficient way to get your data into a DataFrame. In this video, you'll learn how to pull data from CSV files.\n",
    "\n",
    "2. What's a CSV file?\n",
    "00:15 - 00:49\n",
    "CSV, or comma-separated values, is a common data storage file type. It's designed to store tabular data, just like a pandas DataFrame. It's a text file, where each row of data has its own line, and each value is separated by a comma. Almost every database, programming language, and piece of data analysis software can read and write CSV files. That makes it a good storage format if you need to share your data with other people who may be using different tools than you.\n",
    "\n",
    "3. Example CSV file\n",
    "00:49 - 00:59\n",
    "Remember the dogs from the last video? Their data is stored in a CSV file called new_dogs-dot-csv, which looks like this.\n",
    "\n",
    "4. CSV to DataFrame\n",
    "00:59 - 01:09\n",
    "We can put this data in a DataFrame using the handy pandas function, read-underscore-csv, and pass it the file path of the CSV.\n",
    "\n",
    "5. DataFrame manipulation\n",
    "01:09 - 01:20\n",
    "Now that the data is in DataFrame form, we can manipulate it using some of the functions from earlier in the course. Here, we'll add a body mass index column.\n",
    "\n",
    "6. DataFrame to CSV\n",
    "01:20 - 01:42\n",
    "Now that we've changed the data let's create an updated CSV file to share with the dogs' owners. To convert a DataFrame to a CSV, we can use new_dogs dot to-underscore-csv, and pass in a new file path. If we take a look at the new file, it contains the BMI column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df47a26-7818-443e-912e-0891034a364b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
