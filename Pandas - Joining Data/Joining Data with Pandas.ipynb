{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4066048-4af9-4a86-ba20-45fe55e5a7ef",
   "metadata": {},
   "source": [
    "# Joining Data with Pandas\n",
    "\n",
    "**Description**\n",
    "Being able to combine and work with multiple datasets is an essential skill for \n",
    "any aspiring Data Scientist. pandas is a crucial cornerstone of the Python data \n",
    "science ecosystem, with Stack Overflow recording 5 million views for pandas questions. \n",
    "Learn to handle multiple DataFrames by combining, organizing, joining, and reshaping \n",
    "them using pandas. You'll work with datasets from the World Bank and the City Of \n",
    "Chicago. You will finish the course with a solid skillset for data-joining in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c8060-8b7a-43bb-872d-35299b45e438",
   "metadata": {},
   "source": [
    "## Data Merging Basics\n",
    "\n",
    "Learn how you can merge disparate data using inner joins. By combining information \n",
    "from multiple sources you’ll uncover compelling insights that may have previously \n",
    "been hidden. You’ll also learn how the relationship between those sources, such \n",
    "as *one-to-one* or *one-to-many*, can affect your result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a18b5-b177-43ff-b204-36826622ec36",
   "metadata": {},
   "source": [
    "### Inner Join\n",
    "\n",
    "**Your first inner join**\n",
    "\n",
    "You have been tasked with figuring out what the most popular types of fuel used in \n",
    "Chicago taxis are. To complete the analysis, you need to merge the taxi_owners and \n",
    "taxi_veh tables together on the vid column. You can then use the merged table along \n",
    "with the `.value_counts()` method to find the most common fuel_type.\n",
    "\n",
    "Since you'll be working with pandas throughout the course, the package will be preloaded \n",
    "for you as pd in each exercise in this course. Also the taxi_owners and taxi_veh \n",
    "DataFrames are loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ea0f9d5-2392-4cd0-ae15-fed9163f4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxi Owners: \n",
      "         rid   vid                          owner                address    zip\n",
      "1352  T3753  3753                   3753 EJM INC  4118 W. LAWRENCE AVE.  60630\n",
      "2073  T3780  3780                 CITY TAXI INC.    4536 N. ELSTON AVE.  60630\n",
      "1563  T2124  2124           ALEXIS CAB CO., INC.  2945 W. PETERSON AVE.  60659\n",
      "462   T2991  2991                    KIM CAB INC  4626 W. CORNELIA AVE.  60641\n",
      "2437  T6968  6968             B & B TAXI CAB INC    3351 W. ADDISON ST.  60618\n",
      "2459   T232   232                 BABY CAB CORP.    2617 S. WABASH AVE.  60616\n",
      "2803  T3979  3979                 3979 TAXI CORP    9696 W. FOSTER AVE.  60656\n",
      "2516  T2599  2599  STEFANIE AND AUDREY CAB CORP.    9696 W. FOSTER AVE.  60656\n",
      "Shape:  (3519, 5) \n",
      "\n",
      "Taxi Vehicles: \n",
      "        vid     make    model  year fuel_type                owner\n",
      "2627  2668   TOYOTA    CAMRY  2015    HYBRID  CHICAGO CAB 2 CORP.\n",
      "2573  1140     FORD   ESCAPE  2011    HYBRID          NECT 20 LLC\n",
      "158   3059   TOYOTA    CAMRY  2014    HYBRID           PEACE INC.\n",
      "2615  4878   TOYOTA    CAMRY  2013    HYBRID     JUBILEE CAB CORP\n",
      "405   3380   TOYOTA   SIENNA  2018  GASOLINE   HASAN & HOSAIN INC\n",
      "1253  1763     FORD   ESCAPE  2012    HYBRID     AUGUST CAB CORP.\n",
      "967   2203  HYUNDAI  ELANTRA  2018  GASOLINE    NEMESIS CAB CORP.\n",
      "2446  6213   TOYOTA    PRIUS  2015    HYBRID           PEACE INC.\n",
      "Shape:  (3519, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data into DataFrames\n",
    "taxi_owners = pd.read_pickle('taxi_owners.p')\n",
    "print('Taxi Owners: \\n',taxi_owners.sample(8))\n",
    "print('Shape: ',taxi_owners.shape,'\\n')\n",
    "\n",
    "taxi_veh = pd.read_pickle('taxi_vehicles.p')\n",
    "print('Taxi Vehicles: \\n',taxi_veh.sample(8))\n",
    "print('Shape: ',taxi_own_veh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb796e70-e42b-477c-ac9c-fc3c5fec511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year',\n",
      "       'fuel_type', 'owner_y'],\n",
      "      dtype='object') \n",
      "\n",
      "Taxi Owners and Vehicles:\n",
      "         rid   vid  ...               fuel_type                              owner_y\n",
      "2460  T3051  3051  ...                GASOLINE                        Z J A CAB INC\n",
      "181   T4012  4012  ...                  HYBRID                      TRAVEL SURF INC\n",
      "2821  T6747  6747  ...                  HYBRID  TAXI MEDALLION GROUP, LLC SERIES IV\n",
      "3370  T1279  1279  ...  COMPRESSED NATURAL GAS                          NECT 11 LLC\n",
      "1198  T5642  5642  ...                  HYBRID                          ASHRAF CORP\n",
      "329   T6344  6344  ...                GASOLINE                       MYNEWLOVE INC.\n",
      "2676  T2375  2375  ...                  HYBRID          CHICAGO MEDALLION NINE, LLC\n",
      "1110  T2352  2352  ...                  HYBRID                   NEXTGEN TAXI I INC\n",
      "\n",
      "[8 rows x 10 columns]\n",
      "Shape:  (3519, 10)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Merge taxi_owners with taxi_veh on the column vid, and save the result \n",
    "# to taxi_own_veh.\n",
    "# Merge the taxi_owners and taxi_veh tables\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid')\n",
    "\n",
    "# Print the column names of the taxi_own_veh\n",
    "print(taxi_own_veh.columns,'\\n')\n",
    "\n",
    "# Print taxi owners and vehicles table\n",
    "print('Taxi Owners and Vehicles:\\n',taxi_own_veh.sample(8))\n",
    "print('Shape: ',taxi_own_veh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a53ed2da-4444-4ad3-9434-aed16f848fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year',\n",
      "       'fuel_type', 'owner_veh'],\n",
      "      dtype='object') \n",
      "\n",
      "Taxi Owners and Vehicles: \n",
      "         rid   vid                owner_own  ...  year fuel_type                owner_veh\n",
      "3377  T6002  6002             BRANDON INC.  ...  2017    HYBRID             BRANDON INC.\n",
      "345   T3247  3247               Z L R CORP  ...  2015    HYBRID               Z L R CORP\n",
      "2589   T714   714          JZG TRANSIT CO.  ...  2016    HYBRID          JZG TRANSIT CO.\n",
      "1396  T4678  4678       TRIPS AND TIPS INC  ...  2014    HYBRID       TRIPS AND TIPS INC\n",
      "1528   T384   384      MASHAALLAH HNZ CORP  ...  2018    HYBRID      MASHAALLAH HNZ CORP\n",
      "437   T5410  5410  SANTORINI TWO CAB CORP.  ...  2016    HYBRID  SANTORINI TWO CAB CORP.\n",
      "1342  T3477  3477            GHANA CAN INC  ...  2015    HYBRID            GHANA CAN INC\n",
      "2527  T1787  1787               MAKENA INC  ...  2016    HYBRID               MAKENA INC\n",
      "\n",
      "[8 rows x 10 columns]\n",
      "Shape:  (3519, 10)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2; Set the left and right table suffixes for overlapping columns of the merge \n",
    "# to _own and _veh, respectively.\n",
    "\n",
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
    "\n",
    "# Print the column names of taxi_own_veh\n",
    "print(taxi_own_veh.columns,'\\n')\n",
    "\n",
    "# Print taxi owners and vehicles table\n",
    "print('Taxi Owners and Vehicles: \\n',taxi_own_veh.sample(8))\n",
    "print('Shape: ',taxi_own_veh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627a86ba-55f2-45fa-b640-3a512f39e50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuel_type\n",
      "HYBRID                    2792\n",
      "GASOLINE                   611\n",
      "FLEX FUEL                   89\n",
      "COMPRESSED NATURAL GAS      27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Select the fuel_type column from taxi_own_veh and print the value_counts() \n",
    "# to find the most popular fuel_types used\n",
    "\n",
    "# Merge the taxi_owners and taxi_veh tables setting a suffix\n",
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own','_veh'))\n",
    "\n",
    "# Print the value_counts to find the most popular fuel_type\n",
    "print(taxi_own_veh['fuel_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0961fe-481b-4a4f-ac3c-1152b18a1042",
   "metadata": {},
   "source": [
    "**Inner joins and number of rows returned**\n",
    "\n",
    "All of the merges you have studied to this point are called inner joins. It is \n",
    "necessary to understand that inner joins only return the rows with matching \n",
    "values in both tables. You will explore this further by reviewing the merge \n",
    "between the wards and census tables, then comparing it to merges of copies of \n",
    "these tables that are slightly altered, named wards_altered, and census_altered. \n",
    "The first row of the wards column has been changed in the altered tables. You \n",
    "will examine how this affects the merge between them. The tables have been \n",
    "loaded for you.\n",
    "\n",
    "For this exercise, it is important to know that the wards and census tables \n",
    "start with 50 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e578ab5-b5a6-481d-9949-4e8b90e82642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wards: \n",
      "    ward               alderman                        address    zip\n",
      "18   19      Matthew J. O'Shea     10400 SOUTH WESTERN AVENUE  60643\n",
      "8     9       Anthony A. Beale            34 EAST 112TH PLACE  60628\n",
      "17   18      Derrick G. Curtis        8359 SOUTH PULASKI ROAD  60652\n",
      "40   41  Anthony V. Napolitano       7442 NORTH HARLEM AVENUE  60631\n",
      "4     5     Leslie A. Hairston          2325 EAST 71ST STREET  60649\n",
      "29   30      Ariel E. Reyboras    3559 NORTH MILWAUKEE AVENUE  60641\n",
      "24   25   Daniel \"Danny\" Solis  1800 SOUTH BLUE ISLAND AVENUE  60608\n",
      "38   39       Margaret Laurino      4404 WEST LAWRENCE AVENUE  60630\n",
      "Shape:  (50, 4) \n",
      "\n",
      "Census: \n",
      "    ward  pop_2000  pop_2010 change                                 address    zip\n",
      "35   36     63376     54766   -14%            2918 NORTH RUTHERFORD AVENUE  60634\n",
      "1     2     54361     55805     3%                WM WASTE MANAGEMENT 1500  60622\n",
      "24   25     55954     54539    -3%           1632-1746 SOUTH MILLER STREET  60608\n",
      "15   16     50205     51954     3%                  6036 SOUTH WOOD STREET  60636\n",
      "25   26     56841     53516    -6%  LITTLE CUBS FIELD COMFORT STATION 1400  60622\n",
      "7     8     54039     51687    -4%              1346-1352 EAST 75TH STREET  60649\n",
      "39   40     58652     55319    -6%              5536 NORTH ARTESIAN AVENUE  60645\n",
      "30   31     65045     53724   -17%               2854 NORTH KEATING AVENUE  60641\n",
      "Shape:  (50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "wards = pd.read_pickle('ward.p')\n",
    "print('Wards: \\n',wards.sample(8))\n",
    "print('Shape: ',wards.shape,'\\n')\n",
    "\n",
    "# Load data into DataFrames\n",
    "census = pd.read_pickle('census.p')\n",
    "print('Census: \\n',census.sample(8))\n",
    "print('Shape: ',census.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9f9d4d-58bc-4aea-8b46-2c0198934b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ward Census: \n",
      "    ward                alderman                           address    zip\n",
      "24   25    Daniel \"Danny\" Solis     1800 SOUTH BLUE ISLAND AVENUE  60608\n",
      "10   11  Patrick Daley Thompson         3659 SOUTH HALSTED STREET  60609\n",
      "32   33            Deborah Mell        3001 WEST IRVING PARK ROAD  60618\n",
      "28   29        Chris Taliaferro            6272 WEST NORTH AVENUE  60639\n",
      "41   42          Brendan Reilly  325 WEST HURON STREET, SUITE 510  60654\n",
      "42   43          Michelle Smith         2523 NORTH HALSTED STREET  60614\n",
      "35   36        Gilbert Villegas                6934 WEST DIVERSEY  60607\n",
      "16   17          David H. Moore         7313 SOUTH ASHLAND AVENUE  60636 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "census = pd.read_pickle('ward.p')\n",
    "print('Ward Census: \\n',wards_census.sample(8),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9ec02c7-6efe-4892-b916-5173aa82862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649 \n",
      "\n",
      "wards_census table shape: (50, 9)\n"
     ]
    }
   ],
   "source": [
    "# Merge wards and census on the ward column and save the result to wards_census.\n",
    "# Merge the wards and census tables on the ward column\n",
    "wards_census = wards.merge(census, on='ward')\n",
    "\n",
    "# Validate data\n",
    "print(wards.head(),'\\n')\n",
    "\n",
    "# Print the shape of wards_census\n",
    "print('wards_census table shape:', wards_census.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb95805b-a484-4b9b-8195-35da9b6414fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward\n",
      "0   63\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n"
     ]
    }
   ],
   "source": [
    "# Copying wards table and changing the first ward value\n",
    "wards_altered = wards.copy()\n",
    "wards_altered.loc[0,'ward'] = 63\n",
    "\n",
    "# Print the first few rows of the wards_altered table to view the change \n",
    "print(wards_altered[['ward']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c494554a-1baa-432a-beed-643042bacb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wards_altered_census table shape: (49, 9)\n"
     ]
    }
   ],
   "source": [
    "# Merge the wards_altered and census tables on the ward column, and notice the \n",
    "# difference in returned rows.\n",
    "\n",
    "# Merge the wards_altered and census tables on the ward column\n",
    "wards_altered_census = wards_altered.merge(census, on='ward')\n",
    "\n",
    "# Print the shape of wards_altered_census\n",
    "print('wards_altered_census table shape:', wards_altered_census.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f95047-8979-431e-b2cc-435e1398ee87",
   "metadata": {},
   "source": [
    "### One-to-many Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dccc4-a7aa-4118-bc36-4ed234ee8de6",
   "metadata": {},
   "source": [
    "**One-to-many merge**\n",
    "\n",
    "A business may have one or multiple owners. In this exercise, you will continue \n",
    "to gain experience with one-to-many merges by merging a table of business owners, \n",
    "called biz_owners, to the licenses table. Recall from the video lesson, with a \n",
    "one-to-many relationship, a row in the left table may be repeated if it is related \n",
    "to multiple rows in the right table. In this lesson, you will explore this further \n",
    "by finding out what is the most common business owner title. (i.e., secretary, CEO, \n",
    "or vice president)\n",
    "\n",
    "The licenses and biz_owners DataFrames are loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54d1c1aa-c7b8-45ca-9b55-fe2938c645c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Licenses: \n",
      "      account ward  aid                    business                   address    zip\n",
      "4716  310354   27  763  WASHINGTON FOOD MART, INC.  2100 W WASHINGTON BLVD 1  60612\n",
      "7280  387360   25  895      ELLE NAILS SPA 1, LTD.          912 W MADISON ST  60607\n",
      "1537  230053   15  NaN           SANCHEZ GROCERIES            2042 W 51ST ST  60609\n",
      "9599   67559    8  NaN          DIALLO & TAILORING  8647 S COTTAGE GROVE AVE  60619\n",
      "4080  294963   22  197           LA VILLITA TRAVEL          3851 W 26TH ST 1  60623\n",
      "8352   47568   24  NaN       SAM'S MUFFLER & BRAKE   3818 W ROOSEVELT RD 1ST  60624\n",
      "8488   50268   25  829                 BUTCH'S TAP        1801 W 19TH ST 1ST  60608\n",
      "1067  212040   35  NaN       GRANITE GALLERY, INC.       3430 W HENDERSON ST  60618\n",
      "Shape:  (10000, 6) \n",
      "\n",
      "Business Owners: \n",
      "       account first_name  last_name            title\n",
      "6833   277997     SANDRA   WECHSLER            OTHER\n",
      "1541    19580    IGNACIO      LOPEZ            OTHER\n",
      "7104     2808      CHERI        NaN        PRESIDENT\n",
      "17027  426989        POL      SIKAR  MANAGING MEMBER\n",
      "17557    4595    CHARLES    NEWSOME        SECRETARY\n",
      "14111  366965      FRANK   GONZALEZ        PRESIDENT\n",
      "16762  419438    PATRICK  O'CONNELL       INDIVIDUAL\n",
      "8003   290554       BETH  MACDONALD  MANAGING MEMBER\n",
      "Shape:  (21352, 4) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "licenses = pd.read_pickle('licenses.p')\n",
    "print('Licenses: \\n',licenses.sample(8))\n",
    "print('Shape: ',licenses.shape,'\\n')\n",
    "\n",
    "# Load data into DataFrames\n",
    "biz_owners = pd.read_pickle('business_owners.p')\n",
    "print('Business Owners: \\n',biz_owners.sample(8))\n",
    "print('Shape: ',biz_owners.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cb69d04-d89c-4d84-af49-b7674888d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (19497, 9)\n",
      "                 account\n",
      "title                   \n",
      "PRESIDENT           6259\n",
      "SECRETARY           5205\n",
      "SOLE PROPRIETOR     1658\n",
      "OTHER               1200\n",
      "VICE PRESIDENT       970\n"
     ]
    }
   ],
   "source": [
    "# Merge the licenses and biz_owners table on account\n",
    "licenses_owners = licenses.merge(biz_owners, on='account')\n",
    "print('Shape: ',licenses_owners.shape)\n",
    "\n",
    "# Group the results by title then count the number of accounts\n",
    "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "\n",
    "# Sort the counted_df in desending order\n",
    "sorted_df = counted_df.sort_values('account',ascending=False)\n",
    "\n",
    "# Use .head() method to print the first few rows of sorted_df\n",
    "print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2431fc-9d95-4b85-911f-c2f17f0d5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort pop_vac_lic by vacant, account, andpop_2010 in descending, ascending, and \n",
    "# ascending order respectively. Save it as sorted_pop_vac_lic.\n",
    "\n",
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
    "                                   as_index=False).agg({'account':'count'})\n",
    "\n",
    "# Sort pop_vac_lic and print the results\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant','account','pop_2010'], \n",
    "                                             ascending=[False,True,True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe719198-1d59-47cb-b326-6c5eff75b64a",
   "metadata": {},
   "source": [
    "### Merging Multiple DataFrames\n",
    "\n",
    "**Total riders in a month**\n",
    "\n",
    "Your goal is to find the total number of rides provided to passengers passing \n",
    "through the Wilson station (`station_name == 'Wilson'`) when riding Chicago's \n",
    "public transportation system on weekdays (`day_type == 'Weekday'`) in July (`month == 7`).\n",
    "Luckily, Chicago provides this detailed data, but it is in three different tables. \n",
    "You will work on merging these tables together to answer the question. This data is \n",
    "different from the business related data you have seen so far, but all the information \n",
    "you need to answer the question is provided.\n",
    "\n",
    "The cal, ridership, and stations DataFrames have been loaded for you. \n",
    "The relationship between the tables can be seen in the diagram below.\n",
    "\n",
    "<img title=\"Total Riders in a Month Relations\" alt=\"Total Riders in a Month Relations\" \n",
    "    src=\"Total Riders in a Month Relations.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b5db444-5175-4e27-8bb9-f83e0881f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendar: \n",
      "      year  month  day  day_type\n",
      "91   2019      4    2   Weekday\n",
      "102  2019      4   13  Saturday\n",
      "301  2019     10   29   Weekday\n",
      "297  2019     10   25   Weekday\n",
      "273  2019     10    1   Weekday\n",
      "307  2019     11    4   Weekday\n",
      "219  2019      8    8   Weekday\n",
      "76   2019      3   18   Weekday\n",
      "Shape:  (365, 4) \n",
      "\n",
      "Ridership: \n",
      "      station_id  year  month  day  rides\n",
      "643       40080  2019     10    6   2258\n",
      "2233      41500  2019      2   13   2723\n",
      "472       40080  2019      4   18   4590\n",
      "1618      40540  2019      6    8   4566\n",
      "1584      40540  2019      5    5   3167\n",
      "1178      40120  2019      3   25   2854\n",
      "3062      41660  2019      5   23  21757\n",
      "2367      41500  2019      6   27   2702\n",
      "Shape:  (3285, 5) \n",
      "\n",
      "Stations: \n",
      "     station_id    station_name                     location\n",
      "11       40130            51st       (41.80209, -87.618487)\n",
      "27       40290    Ashland/63rd       (41.77886, -87.663766)\n",
      "19       40210    Damen-Cermak      (41.854517, -87.675975)\n",
      "101      41090    Monroe/State      (41.880745, -87.627696)\n",
      "80       40870       Francisco      (41.966046, -87.701644)\n",
      "114      41240  Addison-O'Hare        (41.94738, -87.71906)\n",
      "49       40530        Diversey      (41.932732, -87.653131)\n",
      "82       40890  O'Hare Airport  (41.97766526, -87.90422307)\n",
      "Shape:  (144, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "cal = pd.read_pickle('cta_calendar.p')\n",
    "print('Calendar: \\n',cal.sample(8))\n",
    "print('Shape: ',cal.shape,'\\n')\n",
    "\n",
    "# Load data into DataFrames\n",
    "ridership = pd.read_pickle('cta_ridership.p')\n",
    "print('Ridership: \\n',ridership.sample(8))\n",
    "print('Shape: ',ridership.shape,'\\n')\n",
    "\n",
    "# Load data into DataFrames\n",
    "stations = pd.read_pickle('cta_stations.p')\n",
    "print('Stations: \\n',stations.sample(8))\n",
    "print('Shape: ',stations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb2d9bd1-71ea-46be-b617-d361b0daf83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_id  year  month  day  rides        day_type\n",
      "0      40010  2019      1    1    576  Sunday/Holiday\n",
      "1      40010  2019      1    2   1457         Weekday\n",
      "2      40010  2019      1    3   1543         Weekday\n",
      "3      40010  2019      1    4   1621         Weekday\n",
      "4      40010  2019      1    5    719        Saturday\n",
      "Shape:  (3285, 6) \n",
      "\n",
      "  station_id  year  month  ...        day_type        station_name                 location\n",
      "0      40010  2019      1  ...  Sunday/Holiday  Austin-Forest Park  (41.870851, -87.776812)\n",
      "1      40010  2019      1  ...         Weekday  Austin-Forest Park  (41.870851, -87.776812)\n",
      "2      40010  2019      1  ...         Weekday  Austin-Forest Park  (41.870851, -87.776812)\n",
      "3      40010  2019      1  ...         Weekday  Austin-Forest Park  (41.870851, -87.776812)\n",
      "4      40010  2019      1  ...        Saturday  Austin-Forest Park  (41.870851, -87.776812)\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "Shape:  (3285, 8) \n",
      "\n",
      "Total number of rides:  140005\n"
     ]
    }
   ],
   "source": [
    "# Merge the ridership and cal tables together, starting with the ridership table \n",
    "# on the left and save the result to the variable ridership_cal. If you code takes \n",
    "# too long to run, your merge conditions might be incorrect.\n",
    "\n",
    "# Merging 2 tables together using multiple key columns\n",
    "ridership_cal = ridership.merge(cal, on=['year','month','day'])\n",
    "\n",
    "print(ridership_cal.head())\n",
    "print('Shape: ',ridership_cal.shape,'\\n')\n",
    "\n",
    "# Extend the previous merge to three tables by also merging the stations table.\n",
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "            \t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "print(ridership_cal_stations.head())\n",
    "print('Shape: ',ridership_cal_stations.shape,'\\n')\n",
    "\n",
    "# Create a variable called filter_criteria to select the appropriate rows \n",
    "# from the merged table so that you can sum the rides column.\n",
    "\n",
    "# Create a filter to filter ridership_cal_stations\n",
    "filter_criteria = ((ridership_cal_stations['month'] == 7) \n",
    "                   & (ridership_cal_stations['day_type'] == 'Weekday') \n",
    "                   & (ridership_cal_stations['station_name'] == 'Wilson'))\n",
    "\n",
    "# Use .loc and the filter to select for rides\n",
    "print('Total number of rides: ',ridership_cal_stations.loc[filter_criteria, 'rides'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7137f-b553-4df3-9aeb-e539eb5ccb4d",
   "metadata": {},
   "source": [
    "**Three table merge**\n",
    "\n",
    "To solidify the concept of a three DataFrame merge, practice another exercise. A \n",
    "reasonable extension of our review of Chicago business data would include looking \n",
    "at demographics information about the neighborhoods where the businesses are. A \n",
    "table with the median income by zip code has been provided to you. You will merge \n",
    "the `licenses` and `wards` tables with this new income-by-zip-code table called `zip_demo`.\n",
    "\n",
    "The licenses, wards, and zip_demo DataFrames have been loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bef16315-1fcd-4391-8b8d-e8b127a098f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations: \n",
      "       zip  income\n",
      "26  60657   88708\n",
      "53  60173   79024\n",
      "40  60655   94524\n",
      "12  60659   50554\n",
      "56  60653   28411\n",
      "22  60638   67045\n",
      "23  60623   31445\n",
      "48  60661  104714\n",
      "Shape:  (66, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "zip_demo = pd.read_pickle('zip_demo.p')\n",
    "print('Stations: \\n',zip_demo.sample(8))\n",
    "print('Shape: ',zip_demo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4d49893-9aa7-406b-96f7-29019cff3576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     account ward  aid  ...             alderman                         address_y  zip_y\n",
      "8669    5265    9  763  ...     Anthony A. Beale               34 EAST 112TH PLACE  60628\n",
      "3783  287775   42  NaN  ...       Brendan Reilly  325 WEST HURON STREET, SUITE 510  60654\n",
      "1444  222383   28  NaN  ...       Jason C. Ervin             2602 WEST 16TH STREET  60612\n",
      "5421  328992   27  942  ...  Walter Burnett, Jr.            4 NORTH WESTERN AVENUE  60612\n",
      "3125  273046   15  NaN  ...     Raymond A. Lopez             1650 WEST 63RD STREET  60636\n",
      "\n",
      "[5 rows x 10 columns]\n",
      "Shape:  (9994, 10) \n",
      "\n",
      "                             income\n",
      "alderman                           \n",
      "Ameya Pawar                 66246.0\n",
      "Anthony A. Beale            38206.0\n",
      "Anthony V. Napolitano       82226.0\n",
      "Ariel E. Reyboras           41307.0\n",
      "Brendan Reilly             110215.0\n",
      "Brian Hopkins               87143.0\n",
      "Carlos Ramirez-Rosa         66246.0\n",
      "Carrie M. Austin            38206.0\n",
      "Chris Taliaferro            55566.0\n",
      "Daniel \"Danny\" Solis        41226.0\n",
      "David H. Moore              33304.0\n",
      "Deborah Mell                66246.0\n",
      "Debra L. Silverstein        50554.0\n",
      "Derrick G. Curtis           65770.0\n",
      "Edward M. Burke             42335.0\n",
      "Emma M. Mitts               36283.0\n",
      "George Cardenas             33959.0\n",
      "Gilbert Villegas            41307.0\n",
      "Gregory I. Mitchell         24941.0\n",
      "Harry Osterman              45442.0\n",
      "Howard B. Brookins, Jr.     33304.0\n",
      "James Cappleman             79565.0\n",
      "Jason C. Ervin              41226.0\n",
      "Joe Moore                   39163.0\n",
      "John S. Arena               70122.0\n",
      "Leslie A. Hairston          28024.0\n",
      "Margaret Laurino            70122.0\n",
      "Marty Quinn                 67045.0\n",
      "Matthew J. O'Shea           59488.0\n",
      "Michael R. Zalewski         42335.0\n",
      "Michael Scott, Jr.          31445.0\n",
      "Michelle A. Harris          32558.0\n",
      "Michelle Smith             100116.0\n",
      "Milagros \"Milly\" Santiago   41307.0\n",
      "Nicholas Sposato            62223.0\n",
      "Pat Dowell                  46340.0\n",
      "Patrick Daley Thompson      41226.0\n",
      "Patrick J. O'Connor         50554.0\n",
      "Proco \"Joe\" Moreno          87143.0\n",
      "Raymond A. Lopez            33959.0\n",
      "Ricardo Munoz               31445.0\n",
      "Roberto Maldonado           68223.0\n",
      "Roderick T. Sawyer          32558.0\n",
      "Scott Waguespack            68223.0\n",
      "Susan Sadlowski Garza       38417.0\n",
      "Tom Tunney                  88708.0\n",
      "Toni L. Foulkes             27573.0\n",
      "Walter Burnett, Jr.         87143.0\n",
      "William D. Burns           107811.0\n",
      "Willie B. Cochran           28024.0\n"
     ]
    }
   ],
   "source": [
    "# Starting with the licenses table, merge to it the zip_demo table on \n",
    "# the zip column. Then merge the resulting table to the wards table on \n",
    "# the ward column. Save result of the three merged tables to a variable \n",
    "# named licenses_zip_ward.\n",
    "\n",
    "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
    "licenses_zip_ward = licenses.merge(zip_demo, on='zip').merge(wards, on='ward')\n",
    "print(licenses_zip_ward.sample(5))\n",
    "print('Shape: ',licenses_zip_ward.shape,'\\n')\n",
    "\n",
    "# Group the results of the three merged tables by the column alderman and \n",
    "# find the median income.\n",
    "\n",
    "# Print the results by alderman and show median income\n",
    "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a799bd6-d66a-4820-a302-a02f4a342db1",
   "metadata": {},
   "source": [
    "**One-to-many merge with multiple tables**\n",
    "\n",
    "In this exercise, assume that you are looking to start a business in the city of \n",
    "Chicago. Your perfect idea is to start a company that uses goats to mow the lawn \n",
    "for other businesses. However, you have to choose a location in the city to put \n",
    "your goat farm. You need a location with a great deal of space and relatively few \n",
    "businesses and people around to avoid complaints about the smell. You will need \n",
    "to merge three tables to help you choose your location. The `land_use` table has \n",
    "info on the percentage of vacant land by city ward. The `census` table has population \n",
    "by `ward`, and the `licenses` table lists businesses by ward.\n",
    "\n",
    "The land_use, census, and licenses tables have been loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6591b551-87fb-4b6f-8b3d-59ec20160432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Use: \n",
      "    ward  residential  commercial  industrial  vacant  other\n",
      "19   20           23           2           3      15     57\n",
      "32   33           42           5           4       1     48\n",
      "42   43           34           9           0       1     56\n",
      "25   26           36           5           4       2     53\n",
      "12   13           49           3           2       1     45\n",
      "43   44           41           6           0       0     53\n",
      "3     4           22          13           0       7     58\n",
      "30   31           46           8           8       0     38\n",
      "Shape:  (50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "land_use = pd.read_pickle('land_use.p')\n",
    "print('Land Use: \\n',land_use.sample(8))\n",
    "print('Shape: ',land_use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e20a339e-79cb-4f6a-9a80-536cb17c6dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ward  pop_2010  vacant  account\n",
      "47    7     51581      19       80\n",
      "12   20     52372      15      123\n",
      "1    10     51535      14      130\n",
      "16   24     54909      13       98\n",
      "7    16     51954      13      156\n"
     ]
    }
   ],
   "source": [
    "# Merge land_use and census on the ward column. Merge the result of this with \n",
    "# licenses on the ward column, using the suffix _cen for the left table and _lic \n",
    "# for the right table. Save this to the variable land_cen_lic.\n",
    "\n",
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, \n",
    "                              on='ward').merge(licenses, \n",
    "                                               on='ward', \n",
    "                                               suffixes=('_cen','_lic'))\n",
    "\n",
    "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'],\n",
    "                                   as_index=False).agg({'account':'count'})\n",
    "\n",
    "# Sort pop_vac_lic and print the results\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant','account','pop_2010'], \n",
    "                                             ascending=[False,True,True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03272db4-5d44-4d19-be38-04a552fe4095",
   "metadata": {},
   "source": [
    "## Merging Tables With Different Join Types\n",
    "\n",
    "Take your knowledge of joins to the next level. In this chapter, you’ll work with \n",
    "TMDb movie data as you learn about left, right, and outer joins. You’ll also discover \n",
    "how to merge a table to itself and merge on a DataFrame index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5547c-201b-46c2-8de3-d999b09e5106",
   "metadata": {},
   "source": [
    "### Left Join\n",
    "\n",
    "**Counting missing rows with left join**\n",
    "\n",
    "The Movie Database is supported by volunteers going out into the world, collecting \n",
    "data, and entering it into the database. This includes financial data, such as \n",
    "movie budget and revenue. If you wanted to know which movies are still missing \n",
    "data, you could use a left join to identify them. Practice using a left join by \n",
    "merging the movies table and the financials table.\n",
    "\n",
    "The movies and financials tables have been loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "895bbc09-87d4-429c-bf87-83519afb7c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies: \n",
      "           id                        title  popularity release_date\n",
      "4723   43074                 Ghostbusters   66.218060   2016-07-14\n",
      "2001    9339                        Click   41.176631   2006-06-22\n",
      "2770   16727                 The Namesake    3.604863   2006-09-02\n",
      "1153  125537  Smiling Fish & Goat On Fire    0.007340   1999-09-16\n",
      "4479    4380              Shall We Dance?   14.231899   2004-10-15\n",
      "3593   11876     The Horseman on the Roof    2.877488   1995-09-20\n",
      "4660   26748                    Lone Star    5.960149   1996-06-21\n",
      "2199    6537                The Orphanage   29.071955   2007-08-27\n",
      "Shape:  (4803, 4) \n",
      "\n",
      "Movie Financials: \n",
      "          id    budget      revenue\n",
      "2378  38448  12000000    1644755.0\n",
      "924    2252  51500000   55112356.0\n",
      "2319  36691  15000000    5024782.0\n",
      "1657  10030  25000000   59192128.0\n",
      "410    8247  85000000  222231186.0\n",
      "1375  24662  32000000    3566637.0\n",
      "2916  11697   3200000    8000000.0\n",
      "2260  10876  13500000    7060876.0\n",
      "Shape:  (3229, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrames\n",
    "movies = pd.read_pickle('mov_movies.p')\n",
    "print('Movies: \\n',movies.sample(8))\n",
    "print('Shape: ',movies.shape,'\\n')\n",
    "\n",
    "financials = pd.read_pickle('mov_financials.p')\n",
    "print('Movie Financials: \\n',financials.sample(8))\n",
    "print('Shape: ',financials.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74cbef-f3b4-4e53-8a30-3ce06dd8e182",
   "metadata": {},
   "source": [
    "### Other Join\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561d1ab-a117-4b77-a45c-4bc1d9f6140d",
   "metadata": {},
   "source": [
    "### merging a table to itself\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0addbae-7ffa-4dbd-a635-a2ac13d4c29d",
   "metadata": {},
   "source": [
    "### Merging on indexes\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad43b6-8c0a-4d8a-85de-187aefca07c0",
   "metadata": {},
   "source": [
    "## Advanced Merging and Concatenating\n",
    "\n",
    "In this chapter, you’ll leverage powerful filtering techniques, including semi-joins and anti-joins. You’ll also learn how to glue DataFrames by vertically combining and using the pandas.concat function to create new datasets. Finally, because data is rarely clean, you’ll also learn how to validate your newly combined data structures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb0384-9954-4180-b71b-30b5d072ccd7",
   "metadata": {},
   "source": [
    "### Filtering Joins\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fef4e-f76a-443f-b8b4-eef615dda683",
   "metadata": {},
   "source": [
    "### Concatenate DataFrames Together Vertically\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53266f-7d5b-479c-b280-3584bc153cfc",
   "metadata": {},
   "source": [
    "### Verifying Integrity\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe34857-ec94-49a4-afd6-ca96f66d0fc6",
   "metadata": {},
   "source": [
    "## Merging Ordered and Time-Series Data\n",
    "\n",
    "In this final chapter, you’ll step up a gear and learn to apply pandas' specialized methods for merging time-series and ordered data together with real-world financial and economic data from the city of Chicago. You’ll also learn how to query resulting tables using a SQL-style format, and unpivot data using the melt method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b881793-aeaf-4ad9-986f-3e67035d022d",
   "metadata": {},
   "source": [
    "### Using `.merge_ordered()`\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ff77a-61d8-467e-aeaf-fdc32e29b260",
   "metadata": {},
   "source": [
    "### Using `.merge_asof()`\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c5c2e-0110-43b4-867c-0f6a706e8615",
   "metadata": {},
   "source": [
    "### Selecting Data with `.query()`\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eac5ba-d990-4cb8-b6a7-522728ee3d9d",
   "metadata": {},
   "source": [
    "### Reshaping Data with `.melt()`\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd950d6-c6aa-4bd0-b202-a34116117b17",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
